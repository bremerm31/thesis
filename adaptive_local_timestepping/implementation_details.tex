\section{Implementation Details}
\label{sec:implementation}

By expressing the algorithm as a discrete event simulation, we can use existing parallelization infrastructure to rapidly and efficiently parallelize the proposed local timestepping algorithm. This section introduces Devastator, the parallel discrete event simulator upon which our implementation is based. Additionally, we outline several performance optimizations made to the algorithm to improve the performance as well as load balancing strategies to achieve good compute resource utilization.

\subsection{Devastator Simulation Framework}
%Need defined TimeWarp, roll back
Devastator (publication forthcoming) is the parallel discrete event simulation (PDES) framework we have used to implemented this work. As with other PDES frameworks, Devastator expects the simulation to be modeled as a discrete number of logical processes (i.e. actors) producing and consuming timestamped events. Once the logical processes and their event processing behaviors have been defined, Devastator handles the task of progressing and maintaining consistency of the distributed parallel execution. To do this, Devastator employs the TimeWarp algorithm~\cite{Jefferson1985} with an asynchronous algorithm for bounding global virtual time (GVT). Devastator was chosen for this work for its emphasis on performance in HPC environments as well as its productive C++14 interface.

PDES frameworks generally fall in one of two categories in how they maintain consistency of the distributed state, these are named optimistic and conservative. Consider the following scenario: a CPU $A$ in the simulation wants to execute event $E$ having timestamp $T$. How can the CPU be sure that no other event $E'$ with timestamp $T'$ where $T' < T$ is going to be generated by some other CPU $B$ and sent to $A$? Conservative methods require all CPUs to synchronize heavily to ensure that $E$ is only ever executed after it can be proven that no such $E'$ is possible. Optimistic methods, like TimeWarp, instead execute events optimistically before knowing that it is safe to so. To deal with the inevitable causality violations (discovering $E'$ only after executing $E$), TimeWarp performs a {\em rollback} to revert the logical process's state to before execution of $E$, then executes $E'$, then $E$, and carries on. Once GVT passes $T$, the CPU knows that no such further events $E'$ can occur, and the event $E$ is {\em committed}.

Optimistic execution enjoys the ability to operate with high performance in regimes of low communication, dynamically, simply by virtue that it always assumes no communication is needed before executing the next event. This makes it an excellent choice for domains where absolute bounds on the needed inter-CPU synchronization are far tighter than what is required in the average case. Simply put, for an application that rarely needs to communicate, it's best to assume it never needs to and then only pay a heavy cost when that assumption fails, rather than synchronizing frequently (as in a conservative execution) only to learn communication isn't required.

 In the case of nonlinear conservation laws, determining whether an event is able to execute without incurring a CFL violation requires determining the domain of dependence for that submesh. Due to pathological examples such as the shockwave for Burgers' equation considered in the introduction, this is an inherently non-local problem. In situ computation of the domain of dependence would greatly increase required communication between submeshes. The locality of this problem can be limited by considering smaller timesteps at the cost of available parallelism. However, in practice we assume that the probability of a remote high-speed wave dramatically increasing $|\Lambda|$ and causing CFL violations is very small. Using optimistic execution, we are able to maintain our local communication stencil without limiting parallelism, and only incur significant overhead when timesteps require refining.

\subsection{Performance related optimizations}
While implementing the above presented push flux and update functions specify a TVD timestepping algorithm, three performance optimizations were necessary to obtain good parallel performance.
\begin{enumerate}
    \item {\em Timestep binning:} While the {\sc compute\_t\_next} allows us to take optimally large timesteps, the local ordering constraint makes this approach suboptimal. As an example consider two neighboring submeshes, which are able to take respective timesteps of 16 (the left submesh) and 17 (the right submesh) time units. During the simulation, the left submesh advances to time 16, and the right submesh advances to time 17. Once the right submesh has advanced, it forces its neighbor to update due to a local ordering violation, and so the left submesh has updated at both times 16 and 17. Using a work-depth analysis, at time 272, this approach requires $3\cdot 16$ (48) updates, and has a depth of $2\cdot 16$ (32). Instead, we propose binning timesteps to the nearest power of two. Specifically, we require that given a certain timestep size ($\Delta t$), we step to largest multiple of the largest power of two multiplied by $\Delta t_{\min}$ less than the given timestep. This naturally synchronizes submeshes and avoids extra updates due to local ordering violations. In the given example, both submeshes would take timesteps of 16. Thus, the work would be $17\cdot 2$ (34) and the depth would be 17. By restricting allowable timestep sizes, we potentially reduce both work and the depth of the simulation.
    \item {\em Reducing unnecessary speculation:} While TimeWarp allows us to speculatively update the submeshes, it is not always wise to do so. If a submesh updates and sends a forced push flux to one neighbor, we know that at that time the neighbor would have to send a push flux back. Therefore, any events executed on the submesh before the neighboring push flux arrives must be rolled back. Therefore, whenever scheduling new updates the submesh inspects its state to determine whether it is still waiting for a message from one of its neighbors. If so, it will simply return without scheduling any further events. Once the messages the submesh is waiting on arrive, it will schedule the next events without having to roll back events.
    \item {\em Avoiding small timesteps due to binning:} While timestep binning reduces the number of synchronizations required due to local ordering violations, it introduces another problem due to the fact that timesteps at submesh boundaries are computed relative to the previous synchronization time. Considering two submeshes that both could step at 7 time units. The timestep binning would make both of these submeshes update at time 4. However, assuming that the push flux from one submesh is delayed, the other submesh would take timesteps of sizes 2 and 1 before being unable to make progress and sending a forced update to the neighbor. Since the timestep is taken relative to the previous synchronization time, the submesh will try to enumerate the bits of its maximum timestep before waiting on a message from its neighbor. This phenomena is highly problematic for parallel discrete event simulation, since once the neighboring message at time 4 arrives, the updates at times 6 (timestep of 2) and 7 (timestep of 1) would have to be rolled back along with any events scheduled due to those later updates. Furthermore, since the timesteps become smaller and smaller, the associated updates are enqueued with a high priority into the event queue and the simulator is more likely to spend time executing events which will be rolled back.  To remedy this, we introduce a heuristic whereby we examine the ratio between the timestep taken if the submesh were synchronized with its neighbors divided by the computed timestep due to a single neighbor, i.e. the value of {\sc compute\_t\_next\_bdry}. If this ratio is greater than or equal to 2, we force that neighbor to update at the current time. The previous optimization (reducing unnecessary speculation) then causes the submesh to wait until the neighbor's push flux has been processed. While this may increase the critical path of simulation depending on the latency associated with sending messages, we have found that in practice this significantly reduces bad speculation.
\end{enumerate}

\subsection{Performance Modeling and Load Balancing}
\label{sec:load-balancing}
To understand the performance results as well as load balance the problem, we estimate the work for a given problem as follows. At a given simulation time $\tau$, the timestep $dt$ taken by cell $j$ can be approximated as
\begin{equation*}
dt_j(\tau) = \Delta t_{\min} 2^{\left\lfloor \log_2 \frac{ \Delta x_j}{2 |\Lambda(\tau, x_j)| \Delta t_{\min}}\right\rfloor},
\end{equation*}
where $\Delta t_{\min}$ is the smallest timestep, $\Delta x_j$ is the cell size, and $|\Lambda|$ corresponds to the wave speed at time $\tau$ in the midpoint of the cell. The $\log_2$  appropriately bins the timesteps.

The mesh partitioning problem follows a 2-phase process of aggregating cells into submeshes and assigning the submeshes to ranks. Cells within each submesh step synchronously enabling efficient utilization of CPU architectures. Although stability requirements necessitate that cells step at the most stringent timestep of cells associated with that submesh, unstructured finite element meshes typically exhibit small variations of timestep sizes in a given neighborhood. Therefore, the synchronous stepping inside a submesh marginally decreases the maximum attainable speed-up.

The mapping of cells to submeshes is denoted by $\pi:\mathbb{Z} \to \mathbb{Z}$.
Since in this paper, we exclusively consider one dimensional problems, we define our partition using a set of ordered splitters $\{s_i\}\subset \mathbb{Z}$ where the submesh $i$ has been assigned the cells with indices $[s_i,s_{i+1})$. The relationship between the splitters and partition function is then given by: for cell $j$, $\pi(j) = i^*$ such that $s_{i^*} \le j < s_{i^*+1}$. %\Cy{also, keep capitalization of $s_i$ vs. $S_i$ consistent}
%\Cy{consider using $j$ as the index for meshes and $i$ as the index for cells}\Max{$j$ is for cells and $i$ is for submeshes. This is consistent with earlier parts of the paper too}
For the generation of $\pi$, we assume no prior knowledge on $\Lambda$ i.e. $|\Lambda| \equiv 1$, and partition solely based on variation in cell sizes. 
Let $w_j$ be the weights assigned to each cell. Each $w_j$ is determined by the smallest allowable timestep on a given submesh, i.e.
\begin{equation*}
w_j = \frac{1}{\min_{1\le r \le n_{el}}\{dt_r(\tau) \, : \, \pi(j) = \pi(r) \}}.
\end{equation*}
Since the partitioner balances work across submeshes, but the work depends on the partitioning, there exists a circular dependency.
Hence, we generate $\pi$ using an iterative procedure. Given weights $\{w_j\}$, we create a partition $\pi$, ensuring each submesh has the same amount of work.
 With the new partition, update the weights $w_j$, which may change based on elements added or removed from a submesh. Repeat this process until some terminating condition is satisfied. In this paper, we stop iterating after 100 iterations. Throughout the iterations, we track the amount of work assigned to the most overworked submesh. At the end of the iterative procedure, we return the partition with the least overworked submesh, i.e. if $\pi_{\ell}$ is the $\ell$-th iteration of the submesh partitioner, 
\begin{equation*}
\pi = \argmin_{\{\pi_{\ell}\}} \max_{0 < i < \nsbmsh} \sum_{j=1}^{n_{el}} \chi_{\{\pi_{\ell}(j) = i\}}(j) w_{j}
\end{equation*}
where $\chi_A$ denotes an indicator function over set $A$. The objective of the first partitioning phase is to specify a problem that can be efficiently executed by the parallel discrete event simulator. The proposed scheme attempts to generate submeshes such that the number of cells updated is approximately equal across all submeshes. However, due to the dependence of work on partitioning, we must also pay attention to the total work. A proposed partitioning may be perfectly load balanced but require a lot more work and therefore be less preferable than a partitioning which is imbalanced but more work optimal, i.e. for which the discrepancy between $w_j$ and $dt_j^{-1}$ is smaller.

%\Cy{whereas the objective of the first phase was to equalize estimated work across submeshes, without using/requiring wavespeed?} 
The second partitioning phase assigns submeshes to ranks. The objective of this phase is to minimize the runtime of the simulation. Let $\rho$ map a submesh to its assigned rank. Since the most overworked rank will determine the rate at which global virtual time is advanced, we estimate the wall-clock time as
\begin{equation}
T = \int_0^{\tend} \max_{0 \le k < n_{ranks}} \sum_{j=1}^{n_{el}}  w_j(\tau) \chi_{\{(\rho \circ \pi)(j) = k\}}(j) \,\mathrm{d} \tau.
\label{eq:lb}
\end{equation}
%\Cy{consider replacing $(\rho \circ \pi)^{-1}(k)$ with $(\rho \circ \pi)(i) = k$ or maybe $i \in (\rho \circ \pi)^{-1}(k)$}
%\Cy{looks like the definition of $w$ has changed since the previous definition to take into account wave speed?}
We remark that for performance results presented in Section~\ref{sec:performance-results}, we consider analytic solutions, thereby yielding a good approximation to $|\Lambda|$ and hence $w_j$. We solve \eqref{eq:lb} using a Gauss-Lobatto quadrature to approximate the integral in time. Given the submesh partition $\pi$ and our assumed wavespeed $\Lambda$, we can formulate this problem as mixed integer programming problem, which we solve using Gurobi~\cite{Gurobi}.  The incorporation of $|\Lambda|$ in \eqref{eq:lb} introduces a discrepancy between the $|\Lambda|$ used for the two partitioning phases. The decision to use different $|\Lambda|$ for the partitioning phases arises from two considerations. First, exactly knowing $|\Lambda|$ is an impractical constraint. Since $|\Lambda|$ is a function of the solution, knowing $|\Lambda|$ implies already knowing the solution to the problem we are interested in solving. Using approximations or even analytic representations of $|\Lambda|$ for determining $\pi$ can be problematic. If we consider one giant submesh and a single cell underestimates $|\Lambda|$, the entire submesh will incur extra work. By ignoring $|\Lambda|$ in during the computation of $\pi$, we inoculate ourselves against adverse effects caused by poor estimates of $|\Lambda|$. The second consideration has to do with partitioner performance. The number of cells is 2-3 orders of magnitude larger than the number of submeshes. Attempting to solve \eqref{eq:lb} for the cell graph would be intractable for large cell counts. By ignoring $|\Lambda|$ in the first partitioning phase, we can use existing fast graph partitioners to generate submeshes and use more sophisticated means to achieve good load balance at the submesh level.

Lastly, we derive upper limits on the speed-up achievable as the ratio of work (i.e. number of cell updates) executed by a standard synchronous timestepping implementation using an MPI runtime divided by the local timestepping Devastator implementation. We calculate the total work for the Devastator runtime as
\begin{equation*}
W^{th}_{deva} = \sum_{j=1}^{n_{el}} \int_0^{\tend} w_{j}(\tau) \, \mathrm{d} \tau.
\end{equation*}
Note that this estimate is a conservative work estimate for the Devastator implementation as it doesn't account for factors such as taking intermediate timesteps between finer and coarser timesteps as well as extra timesteps due to forced updates and rollbacks. For an MPI-based implementation, which steps with uniform timesteps, we compute the work $W^{th}_{MPI}$ as the number of timesteps times the number of elements.
We bound the largest theoretical speed-up by
\begin{equation*}
    S^{th} = \frac{ W^{th}_{MPI}}{W^{th}_{deva}}.
    %\label{eq:Sth}
\end{equation*}
This will provide a baseline to assess how efficient the implementation is.

\subsection{Ease of Implementation}

\begin{figure}
    \centering
\begin{tikzpicture}[->,node distance=0.1cm,
rnd/.style={
  draw=#1,
  rounded corners=8pt,
  line width=1pt,
  align=center,
  text width=3cm,
  minimum height=1cm,
  font=\footnotesize
  }
]
\node[rnd] (AL) {Application Layer};
\node[rnd, below=of AL] (TL) {Timestepping Layer};
\node[rnd, below=of TL] (DL) {Discrete Event Simulation Layer};

\path (AL.east) edge [bend left=90] node[right] {\footnotesize Helper Functions} ([yshift=1mm] TL.east)
      ([yshift=-1mm] TL.east) edge [bend left=90] node[right] { \footnotesize Scheduling Primitives} (DL.east);
\end{tikzpicture}
\caption{Stack Diagram for the Local Timestepping Implementation}
\label{fig:stack-diagram}
\end{figure}

We conclude this section by remarking on the complexity of the implementation. The proposed algorithm can be segmented into three main software layers shown in Figure~\ref{fig:stack-diagram}. At the lowest level is the discrete event simulation layer for which we are using Devastator. Devastator handles all parallelism via the scheduling primitives (Definition~\ref{def:scheduling-primitives}). The layers on top of it schedule events and Devastator ensures that the events are executed in the correct order in a parallel setting. On top of the Devastator layer is the timestepping layer. This layer contains the timestepping logic introduced in Section~\ref{sec:alg}. The complexity of running in an asynchronous context makes this layer difficult to reason about without a tool like loop invariants. However, through judicious specification of helper functions (Definition~\ref{def:helper-functions}) we can prevent the complexity of the timestepping algorithm from seeping into the topmost layer, the application layer. In practice, the timestepping algorithm should be wrapped into a library, and the user would solely need to implement the helper functions. At this highest level, features of the algorithm such as numerical discretization and the form of the conservation laws are specified. Programming at this highest level is effectively identical to programming flat MPI code. The {\sc advance} function is essentially the main kernel of an MPI rank. The only additional calls that need to be supplied deal with assessing the appropriate timestepping size and what to do once a submesh update is either committed or rolled back. This segmentation facilitates the introduction of local timestepping into existing scientific applications without requiring extensive rewriting of code or impeding productive software development in the application layer.
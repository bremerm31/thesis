\section{Forecasting Hurricane Storm Surge}
\label{sec:dgswem}

The details of storm surge modeling were presented in Section~\ref{sec:intro:surge}, and details of the DG method were presented in Section~\ref{sec:intro:dg}. 
In order to understand the communication pattern of the kernel, recall that Runge-Kutta stages are updated according to the following update rule,
\begin{equation*}
\coeffU^{(i)} = \sum_{k=0}^{i-1} \alpha_{ik} \coeffU^{(k)} + \beta_{ik} \Delta t \mathcal{L}^h\left(\coeffU^{(k)}\right),
\end{equation*}
where
\begin{equation}
\mathcal{L}^h \left(\coeffU \right) = \mathcal{M}^{-1}\left( \mathcal{V}\left(\coeffU\right) + \mathcal{S}\left(\coeffU\right) - \mathcal{I}\left(\coeffU\right) \right).
\label{eq:dgkernel}
\end{equation}
The DG method is parallelized by distributing elements across a set of concurrent processes (referred to as {\em ranks}) that cooperate by message passing.
In \eqref{eq:dgkernel}, the volume $\mathcal{V}$, and source $\mathcal{S}$ kernels can be computed entirely locally (independent of other elements).
The interface kernel is the only portion of the DG algorithm that may require non-local information, so elements not on the same rank must communicate over the network.
With explicit timestepping, these equations can be thought of as a stencil code over an irregular graph.
%In comparison, implicit timestepping methods require a global barrier, requiring significantly more network traffic as well as reducing the amount of work that can be completed locally.

%The second aspect that makes DG methods attractive is the ease with which we can achieve high order accuracy.
%For high-order methods in general, the error of the solution, $e$ can be estimated as
%\begin{equation}
%\label{eq:err}
%e = \mathcal{O}(h^{p+1})
%\end{equation}
%where $h$ is some characteristic mesh length scale, and $p$ is the polynomial order of the basis used to approximate the solution of the shallow water equations.  From \eqref{eq:err}, we see that by increasing $p$, we can drastically increase $h$, i.e. coarsen the mesh, without reducing solution quality.
%In practice, there are two caveats to this feature.
%Firstly, the shallow water equations admit discontinuous solutions; at these regions, the convergence rate is degraded to first order, i.e. $e = \mathcal{O}(h)$.
%Secondly, while the number of elements can be drastically reduced for a high-order run, more sophisticated Runge-Kutta timestepping methods are required, reducing both the admissible timestep and increasing the number of stages required to advance the method one timestep.


% \subsection{Source of irregularity}
One of the key aspects of a storm surge code is its ability to simulate inundation.
Due to the numerical discretization, regions of negative water column height may occur throughout the simulation, rendering the shallow water equations meaningless, both mathematically and physically.
To remedy this, an additional slopelimiter is applied after the update kernel.
We use the limiter proposed in \cite{Bunya2009}, which locally examines elements after each update and fixes problematic regions.
One of the key features of this algorithm is its ability to classify elements as either wet or dry.
% Since we are approximating our solution on a static mesh.
The performance implication of this classification is that dry elements require almost no work, thus as the hurricane inundates the coast, elements become wet in localized regions, causing load imbalance.

%%This has been moved into the calibration
%For the purposes of this paper, we have selected a 3.6 million element mesh, %need mesh here
%and are simulating Storm 36 from the FEMA synthetic storm dataset \cite{FEMA}. The simulation was set to run for 16 days simulation time with a timestep of 1 second. The run was performed on NERSC's Edison utilizing 1200 cores.